{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX7aV_IcCuaG"
      },
      "source": [
        "# Hangman challenge using Trie structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG6Pens2t9vT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from itertools import combinations\n",
        "import json\n",
        "import requests\n",
        "import random\n",
        "import string\n",
        "import time\n",
        "import re\n",
        "import collections\n",
        "from collections import Counter\n",
        "\n",
        "try:\n",
        "    from urllib.parse import parse_qs, urlencode, urlparse\n",
        "except ImportError:\n",
        "    from urlparse import parse_qs, urlparse\n",
        "    from urllib import urlencode\n",
        "\n",
        "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
        "\n",
        "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6wcFVgyuBjJ"
      },
      "outputs": [],
      "source": [
        "def func(new_dictionary):\n",
        "    \"\"\"\n",
        "    Count the occurrences of each letter in the new dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    - new_dictionary (list): List of possible words.\n",
        "\n",
        "    Returns:\n",
        "    - collections.Counter: Count of occurrences for each letter.\n",
        "    \"\"\"\n",
        "    dictx = collections.Counter()\n",
        "    for words in new_dictionary:\n",
        "        temp = collections.Counter(words)\n",
        "        for i in temp:\n",
        "            temp[i] = 1\n",
        "            dictx = dictx + temp\n",
        "    return dictx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1Fh0oeqvQJh"
      },
      "outputs": [],
      "source": [
        "# Construct Trie structure to store patterns in dictionary\n",
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_end_of_word = False\n",
        "        self.frequency = 0  # Frequency count indicating the number of words passing through the node\n",
        "\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "        self.trie_count = 0  # Initialize Trie count\n",
        "\n",
        "    def insert(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                node.children[char] = TrieNode()\n",
        "                self.trie_count += 1  # Increment Trie count when a new Trie is created\n",
        "            node = node.children[char]\n",
        "            node.frequency += 1  # Increment frequency count for the node\n",
        "        node.is_end_of_word = True\n",
        "\n",
        "    def construct_from_dictionary(self, dictionary):\n",
        "        for word in dictionary:\n",
        "            for i in range(len(word)):\n",
        "                self.insert(word[i:])  # Create Trie structures starting from each letter in the word\n",
        "\n",
        "\n",
        "    def find_possible_options(self, masked_word, excluded_letters=None):\n",
        "        if excluded_letters is None:\n",
        "            excluded_letters = set()\n",
        "\n",
        "        node = self.root\n",
        "        for char in masked_word:\n",
        "            if char != '_' and char in node.children:\n",
        "                node = node.children[char]\n",
        "            elif char == '_':\n",
        "                break\n",
        "            else:\n",
        "                return []  # No words matching the pattern\n",
        "\n",
        "        options = []\n",
        "        self.traverse_with_frequency(node, masked_word, '', options, excluded_letters)\n",
        "\n",
        "        return options\n",
        "\n",
        "    def traverse_with_frequency(self, node, remaining_pattern, current_word, options, excluded_letters):\n",
        "        if not remaining_pattern:\n",
        "            if node.is_end_of_word:\n",
        "                options.append((current_word, node.frequency))  # Include frequency in options\n",
        "            return\n",
        "\n",
        "        for char, child_node in node.children.items():\n",
        "            if remaining_pattern[0] == '_':\n",
        "                if char not in excluded_letters:\n",
        "                    # Adjust frequency weight based on the number of children and their frequencies\n",
        "                    child_frequency = max(1, child_node.frequency)\n",
        "                    self.traverse_with_frequency(child_node, remaining_pattern[1:], current_word + char, options, excluded_letters)\n",
        "            elif remaining_pattern[0] == char:\n",
        "                self.traverse_with_frequency(child_node, remaining_pattern[1:], current_word + char, options, excluded_letters)\n",
        "\n",
        "    def get_trie_count(self):\n",
        "        \"\"\"\n",
        "        Get the total number of Trie structures created.\n",
        "        \"\"\"\n",
        "        return self.trie_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY-71MW9TycC"
      },
      "outputs": [],
      "source": [
        "# Construct Trie to detect prefix.\n",
        "class PrefixTrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_end_of_prefix = False\n",
        "        self.frequency = 0\n",
        "\n",
        "\n",
        "class PrefixTrie:\n",
        "    def __init__(self):\n",
        "        self.root = PrefixTrieNode()\n",
        "\n",
        "    def insert(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                node.children[char] = PrefixTrieNode()\n",
        "            node = node.children[char]\n",
        "        node.is_end_of_prefix = True\n",
        "        node.frequency += 1\n",
        "\n",
        "    def construct_from_dictionary(self, dictionary, threshold):\n",
        "        for word in dictionary:\n",
        "            for i in range(3, min(6, len(word) + 1)):\n",
        "                prefix = word[:i]\n",
        "                self.insert(prefix)\n",
        "        self.prune_tree(threshold)\n",
        "\n",
        "    def prune_tree(self, threshold):\n",
        "        stack = [(self.root, '')]\n",
        "        while stack:\n",
        "            node, prefix = stack.pop()\n",
        "            if node.is_end_of_prefix and node.frequency < threshold:\n",
        "                del node\n",
        "                continue\n",
        "            for char, child_node in node.children.items():\n",
        "                stack.append((child_node, prefix + char))\n",
        "\n",
        "    def get_prefixes_with_frequency(self):\n",
        "        prefixes_frequency = {}\n",
        "        stack = [(self.root, '')]\n",
        "        while stack:\n",
        "            node, prefix = stack.pop()\n",
        "            if node.is_end_of_prefix:\n",
        "                prefixes_frequency[prefix] = node.frequency\n",
        "            for char, child_node in node.children.items():\n",
        "                stack.append((child_node, prefix + char))\n",
        "        return prefixes_frequency\n",
        "\n",
        "def find_prefix_from_masked_word(masked_word, potential_prefixes):\n",
        "    matched_prefix = []\n",
        "    # Iterate through each potential prefix\n",
        "    for prefix in potential_prefixes:\n",
        "        # Check if the length of the masked word is greater than or equal to the length of the potential prefix\n",
        "        if len(masked_word) >= len(prefix):\n",
        "            # Iterate through each character in the masked word and compare it with the corresponding character in the potential prefix\n",
        "            match = True\n",
        "            for i in range(len(prefix)):\n",
        "                if masked_word[i] != \"_\" and masked_word[i] != prefix[i]:\n",
        "                    match = False\n",
        "                    break\n",
        "            if match:\n",
        "                matched_prefix.append(prefix)  # Return the matching prefix\n",
        "    return matched_prefix  # If no matching prefix is found, return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ay-yAvluC7n"
      },
      "outputs": [],
      "source": [
        "class HangmanAPI(object):\n",
        "    def __init__(self, access_token=None, session=None, timeout=None):\n",
        "        self.hangman_url = self.determine_hangman_url()\n",
        "        self.access_token = access_token\n",
        "        self.session = session or requests.Session()\n",
        "        self.timeout = timeout\n",
        "        self.guessed_letters = []\n",
        "        self.full_dictionary_location = \"/content/drive/MyDrive/words_250000_train.txt\"\n",
        "        self.full_dictionary = self.build_dictionary(self.full_dictionary_location)\n",
        "        self.full_dictionary_common_letter_sorted = collections.Counter(\"\".join(self.full_dictionary)).most_common()\n",
        "        self.current_dictionary = []\n",
        "        self.tries_remains  = 6\n",
        "\n",
        "        self.fulldata_df = self.read_data()\n",
        "        self.hangman_trie_full = Trie()\n",
        "        self.hangman_trie_full.construct_from_dictionary(self.fulldata_df[0])\n",
        "\n",
        "        self.prefix_list = self.prefix_finding()\n",
        "        self.freq_threshold = 200\n",
        "\n",
        "    @staticmethod\n",
        "    def determine_hangman_url():\n",
        "        links = ['https://trexsim.com', 'https://sg.trexsim.com']\n",
        "\n",
        "        data = {link: 0 for link in links}\n",
        "\n",
        "        for link in links:\n",
        "\n",
        "            requests.get(link)\n",
        "\n",
        "            for i in range(10):\n",
        "                s = time.time()\n",
        "                requests.get(link)\n",
        "                data[link] = time.time() - s\n",
        "\n",
        "        link = sorted(data.items(), key=lambda x: x[1])[0][0]\n",
        "        link += '/trexsim/hangman'\n",
        "        return link\n",
        "\n",
        "\n",
        "    def read_data(self):\n",
        "        # Function to read data from a file\n",
        "        with open(self.full_dictionary_location, \"r\") as f:\n",
        "            df = f.read()\n",
        "        x = pd.DataFrame(df.split('\\n'))\n",
        "        return x\n",
        "\n",
        "    def prefix_finding (self):\n",
        "        # finding the prefix list\n",
        "        threshold = 1000\n",
        "        prefix_trie = PrefixTrie()\n",
        "        prefix_trie.construct_from_dictionary(self.fulldata_df[0], threshold)\n",
        "        prefixes_frequency = prefix_trie.get_prefixes_with_frequency()\n",
        "        # Sort the dictionary by frequency\n",
        "        sorted_prefixes_frequency = dict(sorted(prefixes_frequency.items(), key=lambda item: item[1], reverse=True))\n",
        "        prefix_list = [key for key,value in sorted_prefixes_frequency.items() if value > threshold]\n",
        "        return prefix_list\n",
        "\n",
        "\n",
        "    def generate_ngrams(self, masked_word, n):\n",
        "        # constrcting ngram from the mask word\n",
        "        ngrams = []\n",
        "        for i in range(len(masked_word) - n + 1):\n",
        "            window = masked_word[i:i+n]\n",
        "            if '_' in window and any(c.isalpha() for c in window):\n",
        "                ngrams.append(window)\n",
        "        return ngrams\n",
        "\n",
        "    def possible_letters(self, masked_word, excluded_letter=None):\n",
        "        # Initialize an empty list to store possible letter options\n",
        "        possible_options = []\n",
        "        # Get the length of the masked word\n",
        "        ngram_len = len(masked_word)\n",
        "        # Initialize the sum of frequencies of found patterns\n",
        "        freq_sum = 0\n",
        "\n",
        "        # Iterate until the frequency threshold is reached or until ngram_len reaches 1\n",
        "        while freq_sum < self.freq_threshold:\n",
        "            if ngram_len == 1:\n",
        "                break\n",
        "\n",
        "            # Generate possible n-grams from the masked word\n",
        "            possible_ngrams = self.generate_ngrams(masked_word, ngram_len)\n",
        "\n",
        "            # Iterate over each n-gram and find possible options using the Trie\n",
        "            for ngram in possible_ngrams:\n",
        "                current_option = self.hangman_trie_full.find_possible_options(ngram, excluded_letter)\n",
        "                possible_options.extend(current_option)\n",
        "\n",
        "            # Decrease the n-gram length for the next iteration\n",
        "            ngram_len -= 1\n",
        "\n",
        "            # Calculate the sum of frequencies of found options\n",
        "            freq_sum = sum([freq for text, freq in possible_options])\n",
        "\n",
        "        # Print the sum of frequencies and the final n-gram length used\n",
        "\n",
        "        # Weight the possible options based on their frequencies\n",
        "        possible_options_weighted = [text * freq for text, freq in possible_options]\n",
        "\n",
        "        # Concatenate all words into a single string\n",
        "        all_letters = ''.join(possible_options_weighted)\n",
        "\n",
        "        # Count the occurrence of each letter\n",
        "        letter_counts = Counter(all_letters)\n",
        "\n",
        "        # Sort the letters based on their counts in descending order\n",
        "        sorted_alphabets_withcount = sorted(letter_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Extract the sorted letters from the sorted_alphabets_withcount list\n",
        "        sorted_alphabets = [alphabet for alphabet, count in sorted_alphabets_withcount]\n",
        "\n",
        "        # Return the sorted list of letters\n",
        "        return sorted_alphabets\n",
        "\n",
        "\n",
        "    def guess(self, word):\n",
        "        # word input example: \"_ p p _ e \"\n",
        "\n",
        "        # clean the word so that we strip away the space characters\n",
        "        # replace \"_\" with \".\" as \".\" indicates any character in regular expressions\n",
        "        clean_word = word[::2].replace(\"_\",\".\")\n",
        "\n",
        "        # find length of passed word\n",
        "        len_word = len(clean_word)\n",
        "\n",
        "        # remaing spaces\n",
        "        remaining_spaces = clean_word.count('.')\n",
        "\n",
        "        # grab current dictionary of possible words from self object, initialize new possible words dictionary to empty\n",
        "        current_dictionary = self.current_dictionary\n",
        "        new_dictionary = []\n",
        "\n",
        "        # iterate through all of the words in the old plausible dictionary\n",
        "        for dict_word in current_dictionary:\n",
        "            # continue if the word is not of the appropriate length\n",
        "            if len(dict_word) != len_word:\n",
        "                continue\n",
        "\n",
        "            # if dictionary word is a possible match then add it to the current dictionary\n",
        "            if re.match(clean_word, dict_word):\n",
        "                new_dictionary.append(dict_word)\n",
        "\n",
        "        # overwrite old possible words dictionary with updated version\n",
        "        self.current_dictionary = new_dictionary\n",
        "\n",
        "        # add the incorrect gussed letters\n",
        "        if self.guessed_letters and self.guessed_letters[-1] not in clean_word:\n",
        "            self.excluded_letter.append(self.guessed_letters[-1])\n",
        "\n",
        "\n",
        "        # start the guess letter\n",
        "        guess_letter = '!'\n",
        "\n",
        "        # if we have not yet guessed at least 2, start with most common letters,\n",
        "        # in the dictionary of the words with the same length\n",
        "        if (len_word - remaining_spaces) <= 2 or self.tries_remains > 4:\n",
        "            new_dict_string = \"\".join(new_dictionary)\n",
        "            # return most frequently occurring letter in all possible words that hasn't been guessed yet\n",
        "            c = collections.Counter(new_dict_string)\n",
        "            sorted_letter_count = c.most_common()\n",
        "            for letter,_ in sorted_letter_count:\n",
        "                if letter not in self.guessed_letters:\n",
        "                    guess_letter = letter\n",
        "                    break\n",
        "\n",
        "        # now we have at least two letters:\n",
        "        if guess_letter == '!':\n",
        "            predict_letters = self.possible_letters(word[::2])\n",
        "            for letter in predict_letters:\n",
        "                # check if the prediction is alphabet and it is not already suggested\n",
        "                if letter.isalpha() and letter not in self.guessed_letters:\n",
        "                    guess_letter = letter\n",
        "                    break\n",
        "\n",
        "        # check for prefix:\n",
        "        # if there is only 2 left and 3 space left and there is at least one missing in first 4 letter\n",
        "        if self.tries_remains <= 2 and remaining_spaces < 4 and any(letter == \".\" for letter in clean_word[:4]):\n",
        "            found_prefix = find_prefix_from_masked_word(word[::2], self.prefix_list)\n",
        "            full_dict_string = \"\".join(found_prefix)\n",
        "            # return most frequently occurring letter in all possible words that hasn't been guessed yet\n",
        "            c = collections.Counter(full_dict_string)\n",
        "            sorted_letter_count = c.most_common()\n",
        "            for letter,_ in sorted_letter_count:\n",
        "                if letter not in self.guessed_letters:\n",
        "                    guess_letter = letter\n",
        "                    break\n",
        "\n",
        "        # if there was no match: based on words with the same pattern:\n",
        "        if guess_letter == '!':\n",
        "            new_dict_string = \"\".join(new_dictionary)\n",
        "            # return most frequently occurring letter in all possible words that hasn't been guessed yet\n",
        "            c = collections.Counter(new_dict_string)\n",
        "            sorted_letter_count = c.most_common()\n",
        "            for letter,_ in sorted_letter_count:\n",
        "                if letter not in self.guessed_letters:\n",
        "                    guess_letter = letter\n",
        "                    break\n",
        "\n",
        "\n",
        "        # if no word matches in training dictionary, default back to ordering of full dictionary\n",
        "        if guess_letter == '!':\n",
        "            sorted_letter_count = self.full_dictionary_common_letter_sorted\n",
        "            for letter,_ in sorted_letter_count:\n",
        "                if letter not in self.guessed_letters:\n",
        "                    guess_letter = letter\n",
        "                    break\n",
        "\n",
        "        return guess_letter\n",
        "\n",
        "    ##########################################################\n",
        "    # You'll likely not need to modify any of the code below #\n",
        "    ##########################################################\n",
        "\n",
        "    def build_dictionary(self, dictionary_file_location):\n",
        "        text_file = open(dictionary_file_location,\"r\")\n",
        "        full_dictionary = text_file.read().splitlines()\n",
        "        text_file.close()\n",
        "        return full_dictionary\n",
        "\n",
        "    def start_game(self, practice=True, verbose=True):\n",
        "        # reset guessed letters to empty set and current plausible dictionary to the full dictionary\n",
        "        self.guessed_letters = []\n",
        "        self.current_dictionary = self.full_dictionary\n",
        "        self.excluded_letter = []\n",
        "\n",
        "\n",
        "        response = self.request(\"/new_game\", {\"practice\":practice})\n",
        "        if response.get('status')==\"approved\":\n",
        "            game_id = response.get('game_id')\n",
        "            word = response.get('word')\n",
        "            self.tries_remains = response.get('tries_remains')\n",
        "            if verbose:\n",
        "                print(\"Successfully start a new game! Game ID: {0}. # of tries remaining: {1}. Word: {2}.\".format(game_id, self.tries_remains, word))\n",
        "            while self.tries_remains > 0:\n",
        "                # get guessed letter from user code\n",
        "                guess_letter = self.guess(word)\n",
        "\n",
        "                # append guessed letter to guessed letters field in hangman object\n",
        "                self.guessed_letters.append(guess_letter)\n",
        "                if verbose:\n",
        "                    print(\"Guessing letter: {0}\".format(guess_letter))\n",
        "\n",
        "                try:\n",
        "                    res = self.request(\"/guess_letter\", {\"request\":\"guess_letter\", \"game_id\":game_id, \"letter\":guess_letter})\n",
        "                except HangmanAPIError:\n",
        "                    print('HangmanAPIError exception caught on request.')\n",
        "                    continue\n",
        "                except Exception as e:\n",
        "                    print('Other exception caught on request.')\n",
        "                    raise e\n",
        "\n",
        "                if verbose:\n",
        "                    print(\"Sever response: {0}\".format(res))\n",
        "                status = res.get('status')\n",
        "                self.tries_remains = res.get('tries_remains')\n",
        "                if status==\"success\":\n",
        "                    if verbose:\n",
        "                        print(\"Successfully finished game: {0}\".format(game_id))\n",
        "                    return True\n",
        "                elif status==\"failed\":\n",
        "                    reason = res.get('reason', '# of tries exceeded!')\n",
        "                    if verbose:\n",
        "                        print(\"Failed game: {0}. Because of: {1}\".format(game_id, reason))\n",
        "                    return False\n",
        "                elif status==\"ongoing\":\n",
        "                    word = res.get('word')\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\"Failed to start a new game\")\n",
        "        return status==\"success\"\n",
        "\n",
        "    def my_status(self):\n",
        "        return self.request(\"/my_status\", {})\n",
        "\n",
        "    def request(\n",
        "            self, path, args=None, post_args=None, method=None):\n",
        "        if args is None:\n",
        "            args = dict()\n",
        "        if post_args is not None:\n",
        "            method = \"POST\"\n",
        "\n",
        "        # Add `access_token` to post_args or args if it has not already been\n",
        "        # included.\n",
        "        if self.access_token:\n",
        "            # If post_args exists, we assume that args either does not exists\n",
        "            # or it does not need `access_token`.\n",
        "            if post_args and \"access_token\" not in post_args:\n",
        "                post_args[\"access_token\"] = self.access_token\n",
        "            elif \"access_token\" not in args:\n",
        "                args[\"access_token\"] = self.access_token\n",
        "\n",
        "        time.sleep(0.2)\n",
        "\n",
        "        num_retry, time_sleep = 50, 2\n",
        "        for it in range(num_retry):\n",
        "            try:\n",
        "                response = self.session.request(\n",
        "                    method or \"GET\",\n",
        "                    self.hangman_url + path,\n",
        "                    timeout=self.timeout,\n",
        "                    params=args,\n",
        "                    data=post_args,\n",
        "                    verify=False\n",
        "                )\n",
        "                break\n",
        "            except requests.HTTPError as e:\n",
        "                response = json.loads(e.read())\n",
        "                raise HangmanAPIError(response)\n",
        "            except requests.exceptions.SSLError as e:\n",
        "                if it + 1 == num_retry:\n",
        "                    raise\n",
        "                time.sleep(time_sleep)\n",
        "\n",
        "        headers = response.headers\n",
        "        if 'json' in headers['content-type']:\n",
        "            result = response.json()\n",
        "        elif \"access_token\" in parse_qs(response.text):\n",
        "            query_str = parse_qs(response.text)\n",
        "            if \"access_token\" in query_str:\n",
        "                result = {\"access_token\": query_str[\"access_token\"][0]}\n",
        "                if \"expires\" in query_str:\n",
        "                    result[\"expires\"] = query_str[\"expires\"][0]\n",
        "            else:\n",
        "                raise HangmanAPIError(response.json())\n",
        "        else:\n",
        "            raise HangmanAPIError('Maintype was not text, or querystring')\n",
        "\n",
        "        if result and isinstance(result, dict) and result.get(\"error\"):\n",
        "            raise HangmanAPIError(result)\n",
        "        return result\n",
        "\n",
        "class HangmanAPIError(Exception):\n",
        "    def __init__(self, result):\n",
        "        self.result = result\n",
        "        self.code = None\n",
        "        try:\n",
        "            self.type = result[\"error_code\"]\n",
        "        except (KeyError, TypeError):\n",
        "            self.type = \"\"\n",
        "\n",
        "        try:\n",
        "            self.message = result[\"error_description\"]\n",
        "        except (KeyError, TypeError):\n",
        "            try:\n",
        "                self.message = result[\"error\"][\"message\"]\n",
        "                self.code = result[\"error\"].get(\"code\")\n",
        "                if not self.type:\n",
        "                    self.type = result[\"error\"].get(\"type\", \"\")\n",
        "            except (KeyError, TypeError):\n",
        "                try:\n",
        "                    self.message = result[\"error_msg\"]\n",
        "                except (KeyError, TypeError):\n",
        "                    self.message = result\n",
        "\n",
        "        Exception.__init__(self, self.message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA0JWBw8uI4O",
        "outputId": "764ee6b1-4336-4de4-b6db-ae5097e3c91c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully start a new game! Game ID: b14f3f7e2972. # of tries remaining: 6. Word: _ _ _ _ _ _ _ _ _ _ _ _ .\n",
            "Guessing letter: e\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ _ _ _ _ _ _ _ _ _ '}\n",
            "Guessing letter: i\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ i _ _ _ _ _ i _ _ '}\n",
            "Guessing letter: n\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ i n _ _ _ _ i n _ '}\n",
            "Guessing letter: g\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ i n _ _ _ _ i n g '}\n",
            "Guessing letter: r\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'ongoing', 'tries_remains': 4, 'word': '_ _ _ i n _ _ _ _ i n g '}\n",
            "Guessing letter: a\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'ongoing', 'tries_remains': 4, 'word': '_ _ a i n _ _ _ _ i n g '}\n",
            "Guessing letter: t\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'ongoing', 'tries_remains': 3, 'word': '_ _ a i n _ _ _ _ i n g '}\n",
            "Guessing letter: l\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'ongoing', 'tries_remains': 3, 'word': '_ l a i n l _ _ _ i n g '}\n",
            "Guessing letter: o\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'ongoing', 'tries_remains': 3, 'word': '_ l a i n l o o _ i n g '}\n",
            "Guessing letter: p\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'ongoing', 'tries_remains': 3, 'word': 'p l a i n l o o _ i n g '}\n",
            "Guessing letter: k\n",
            "Sever response: {'game_id': 'b14f3f7e2972', 'status': 'success', 'tries_remains': 3, 'word': 'p l a i n l o o k i n g '}\n",
            "Successfully finished game: b14f3f7e2972\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "api.start_game(practice=1, verbose=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
